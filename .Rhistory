dados <- data.frame(
ID = rep(1:n, times = obs_por_individuo)
)
dados <- dados %>%
mutate(
# Variável categórica exemplo (var_cat) binário
var_cat = rep(sample(c(0, 1), n, replace = TRUE), times = obs_por_individuo),
# Variável contínua exemplo (var_cont)
var_cont = unlist(lapply(var_cat, function(s) {
if (s == 1) {
sample(5500:8000, 1)  # Valor para 'var_cat' igual a 1
} else {
sample(1800:3500, 1)  # Valor para 'var_cat' igual a 0
}
})),
# Idade atual dos indivíduos, gerada aleatoriamente entre 0 e 10 anos
idade_atual = unlist(lapply(obs_por_individuo, function(x) runif(x, min = 0, max = 10))),
# Risco do desfecho (para exemplificar) com base em 'var_cat' e 'var_cont'
risco_desfecho  = 0.2 + var_cat * (-0.4) + var_cont * 0.0001
)
# Gerando a variável 'desfecho' a partir do risco, se maior que 0.5 é 1, menor que 0.5 é 0
dados = dados %>%
mutate(desfecho = ifelse(risco_desfecho>0.5,1,0)) %>%
select(-risco_desfecho) # remove o risco
# Carregando os pacotes necessários
library(tidyverse)   # Pacote para manipulação e visualização de dados
library(survival)    # Pacote para análise de sobrevivência
library(icenReg)     # Pacote para análise de sobrevivência com censura intervalar
# Carregando os pacotes necessários
library(tidyverse)   # Pacote para manipulação e visualização de dados
library(survival)    # Pacote para análise de sobrevivência
library(icenReg)     # Pacote para análise de sobrevivência com censura intervalar
n <- 10000 # Número de indivíduos na base de dados
# Número de observações por indivíduo, variando entre 2 e 5 observações
obs_por_individuo <- sample(2:5, n, replace = TRUE)
# Expandindo os IDs para refletir múltiplas observações por indivíduo
dados <- data.frame(
ID = rep(1:n, times = obs_por_individuo)
)
dados <- dados %>%
mutate(
# Variável categórica exemplo (var_cat) binário
var_cat = rep(sample(c(0, 1), n, replace = TRUE), times = obs_por_individuo),
# Variável contínua exemplo (var_cont)
var_cont = unlist(lapply(var_cat, function(s) {
if (s == 1) {
sample(5500:8000, 1)  # Valor para 'var_cat' igual a 1
} else {
sample(1800:3500, 1)  # Valor para 'var_cat' igual a 0
}
})),
# Idade atual dos indivíduos, gerada aleatoriamente entre 0 e 10 anos
idade_atual = unlist(lapply(obs_por_individuo, function(x) runif(x, min = 0, max = 10))),
# Risco do desfecho (para exemplificar) com base em 'var_cat' e 'var_cont'
risco_desfecho  = 0.2 + var_cat * (-0.4) + var_cont * 0.0001
)
# Gerando a variável 'desfecho' a partir do risco, se maior que 0.5 é 1, menor que 0.5 é 0
dados = dados %>%
mutate(desfecho = ifelse(risco_desfecho>0.5,1,0)) %>%
select(-risco_desfecho) # remove o risco
df_surv = dados %>%
group_by(ID) %>%
summarise(
left = ifelse(
any(desfecho == 1),
max(idade_atual[idade_atual < min(idade_atual[desfecho == 1], na.rm = T)
& desfecho == 0], na.rm = T),
max(idade_atual) # Caso não tenha ocorrência do evento, a maior idade é registrada
),
right = ifelse(any(desfecho == 1),
min(idade_atual[desfecho == 1], na.rm = T),
NA), # Caso o evento não tenha ocorrido, substitui por NA
cens = ifelse(any(desfecho == 1), 1, 0),  # Indica se o evento foi observado (1) ou censurado (0)
var_cat = first(var_cat),   # Variáveis de covariáveis para análise
var_cont = first(var_cont)
) %>%
ungroup() %>%
mutate(left = ifelse(left < 0, 0, left))  # Garante que 'left' não seja negativo
# Função para criar o vetor de tempos (tau) a partir dos intervalos censurados
# O uso de digitos de arrendondamento é contribuição de Sofia Aguiar
# a fim de evitar erros em bases meiores que 10 mil
cria.tau <- function(data, digits = 6) {
l <- data$left
r <- data$right
# Arredonda os valores para evitar pequenas diferenças numéricas
l <- round(l, digits = digits)
r <- round(r, digits = digits)
tau <- sort(unique(c(l, r[is.finite(r)])))  # Combina os tempos de censura
return(tau)
}
# Função para inicializar a função de sobrevivência com base no vetor tau
S.ini <- function(tau){
m<-length(tau)
ekm<-survfit(Surv(tau[1:m-1],rep(1,m-1))~1)
So<-c(1,ekm$surv)
p <- -diff(So)
return(p)
}
# Função para construir a matriz A de intervalos de censura
cria.A <- function(data,tau){
tau12 <- cbind(tau[-length(tau)],tau[-1]) # Cria os intervalos [tau[i], tau[i+1]]
interv <- function(x,inf,sup) ifelse(x[1]>=inf & x[2]<=sup,1,0)
A <- apply(tau12,1,interv,inf=data$left,sup=data$right)
id.lin.zero <- which(apply(A==0, 1, all)) # Matriz de censura
if(length(id.lin.zero)>0) A <- A[-id.lin.zero, ] # Filtra intervalos não observados
return(A)
}
# Função de Turnbull, que realiza a estimação iterativa da função de sobrevivência
Turnbull <- function(p, A, data, eps=1e-3,
iter.max=200, verbose=FALSE){
n<-nrow(A)
m<-ncol(A)
Q<-matrix(1,m)
iter <- 0
repeat {
iter <- iter + 1
diff<- (Q-p)
maxdiff<-max(abs(as.vector(diff))) # Diferença máxima entre iterações
if (verbose)
print(maxdiff)
if (maxdiff<eps | iter>=iter.max)
break
Q<-p
C<-A%*%p
p<-p*((t(A)%*%(1/C))/n) # Atualiza as estimativas de probabilidade
}
cat("Iterations = ", iter,"\n")
cat("Max difference = ", maxdiff,"\n")
cat("Convergence criteria: Max difference < 1e-3","\n")
dimnames(p)<-list(NULL,c("P Estimate"))
surv<-round(c(1,1-cumsum(p)),digits=5)
right <- data$right
if(any(!(is.finite(right)))){
t <- max(right[is.finite(right)])
return(list(time=tau[tau<t],surv=surv[tau<t]))
}
else
return(list(time=tau,surv=surv)) # Retorna a função de sobrevivência
}
# Estimação da função de sobrevivência para 'var_cat' igual a 0 e 1
dat1 = df_surv[df_surv$var_cat == 0,]
dat1$right[is.na(dat1$right)] = Inf
tau = cria.tau(dat1)
p = S.ini(tau = tau)
A = cria.A(data = dat1, tau = tau)
tb1 = Turnbull(p, A, dat1)
dat1 = df_surv[df_surv$var_cat == 1,]
dat1$right[is.na(dat1$right)] = Inf
tau = cria.tau(dat1)
p = S.ini(tau = tau)
A = cria.A(data = dat1, tau = tau)
tb2 = Turnbull(p, A, dat1)
# Visualização das funções de sobrevivência para os dois grupos
par(mfrow = c(1, 1))
plot(tb1$time, tb1$surv, col = "red", type = "s", ylim = c(0, 1), xlim = c(0, 10),
xlab = "Tempo em anos", ylab = "S(t)")
lines(tb2$time, tb2$surv, col = "blue", type = "s")
legend(7.5, 0.9, lty = 1, col = c("red", "blue"), c("Categoria 0", "Categoria 1"),
bty = "n", cex = 0.9)
m = max(summary(df_surv$right))  # Máximo dos valores de censura
li = df_surv$left
ui = ifelse(is.na(df_surv$right), m + 1000, df_surv$right)  # Ajuste para censura direita
# Ajuste do modelo de Cox para a variável categórica
fit1 = ic_sp(cbind(li, ui) ~ var_cat, model = 'ph', bs_samples = 100, data = df_surv)
# Carregando os pacotes necessários
library(tidyverse)   # Pacote para manipulação e visualização de dados
library(survival)    # Pacote para análise de sobrevivência
library(icenReg)     # Pacote para análise de sobrevivência com censura intervalar
# Carregando os pacotes necessários
library(tidyverse)   # Pacote para manipulação e visualização de dados
library(survival)    # Pacote para análise de sobrevivência
library(icenReg)     # Pacote para análise de sobrevivência com censura intervalar
n <- 1000 # Número de indivíduos na base de dados
# Número de observações por indivíduo, variando entre 2 e 5 observações
obs_por_individuo <- sample(2:5, n, replace = TRUE)
# Expandindo os IDs para refletir múltiplas observações por indivíduo
dados <- data.frame(
ID = rep(1:n, times = obs_por_individuo)
)
dados <- dados %>%
mutate(
# Variável categórica exemplo (var_cat) binário
var_cat = rep(sample(c(0, 1), n, replace = TRUE), times = obs_por_individuo),
# Variável contínua exemplo (var_cont)
var_cont = unlist(lapply(var_cat, function(s) {
if (s == 1) {
sample(5500:8000, 1)  # Valor para 'var_cat' igual a 1
} else {
sample(1800:3500, 1)  # Valor para 'var_cat' igual a 0
}
})),
# Idade atual dos indivíduos, gerada aleatoriamente entre 0 e 10 anos
idade_atual = unlist(lapply(obs_por_individuo, function(x) runif(x, min = 0, max = 10))),
# Risco do desfecho (para exemplificar) com base em 'var_cat' e 'var_cont'
risco_desfecho  = 0.2 + var_cat * (-0.4) + var_cont * 0.0001
)
# Gerando a variável 'desfecho' a partir do risco, se maior que 0.5 é 1, menor que 0.5 é 0
dados = dados %>%
mutate(desfecho = ifelse(risco_desfecho>0.5,1,0)) %>%
select(-risco_desfecho) # remove o risco
df_surv = dados %>%
group_by(ID) %>%
summarise(
left = ifelse(
any(desfecho == 1),
max(idade_atual[idade_atual < min(idade_atual[desfecho == 1], na.rm = T)
& desfecho == 0], na.rm = T),
max(idade_atual) # Caso não tenha ocorrência do evento, a maior idade é registrada
),
right = ifelse(any(desfecho == 1),
min(idade_atual[desfecho == 1], na.rm = T),
NA), # Caso o evento não tenha ocorrido, substitui por NA
cens = ifelse(any(desfecho == 1), 1, 0),  # Indica se o evento foi observado (1) ou censurado (0)
var_cat = first(var_cat),   # Variáveis de covariáveis para análise
var_cont = first(var_cont)
) %>%
ungroup() %>%
mutate(left = ifelse(left < 0, 0, left))  # Garante que 'left' não seja negativo
# Função para criar o vetor de tempos (tau) a partir dos intervalos censurados
# O uso de digitos de arrendondamento é contribuição de Sofia Aguiar
# a fim de evitar erros em bases meiores que 10 mil
cria.tau <- function(data, digits = 6) {
l <- data$left
r <- data$right
# Arredonda os valores para evitar pequenas diferenças numéricas
l <- round(l, digits = digits)
r <- round(r, digits = digits)
tau <- sort(unique(c(l, r[is.finite(r)])))  # Combina os tempos de censura
return(tau)
}
# Função para inicializar a função de sobrevivência com base no vetor tau
S.ini <- function(tau){
m<-length(tau)
ekm<-survfit(Surv(tau[1:m-1],rep(1,m-1))~1)
So<-c(1,ekm$surv)
p <- -diff(So)
return(p)
}
# Função para construir a matriz A de intervalos de censura
cria.A <- function(data,tau){
tau12 <- cbind(tau[-length(tau)],tau[-1]) # Cria os intervalos [tau[i], tau[i+1]]
interv <- function(x,inf,sup) ifelse(x[1]>=inf & x[2]<=sup,1,0)
A <- apply(tau12,1,interv,inf=data$left,sup=data$right)
id.lin.zero <- which(apply(A==0, 1, all)) # Matriz de censura
if(length(id.lin.zero)>0) A <- A[-id.lin.zero, ] # Filtra intervalos não observados
return(A)
}
# Função de Turnbull, que realiza a estimação iterativa da função de sobrevivência
Turnbull <- function(p, A, data, eps=1e-3,
iter.max=200, verbose=FALSE){
n<-nrow(A)
m<-ncol(A)
Q<-matrix(1,m)
iter <- 0
repeat {
iter <- iter + 1
diff<- (Q-p)
maxdiff<-max(abs(as.vector(diff))) # Diferença máxima entre iterações
if (verbose)
print(maxdiff)
if (maxdiff<eps | iter>=iter.max)
break
Q<-p
C<-A%*%p
p<-p*((t(A)%*%(1/C))/n) # Atualiza as estimativas de probabilidade
}
cat("Iterations = ", iter,"\n")
cat("Max difference = ", maxdiff,"\n")
cat("Convergence criteria: Max difference < 1e-3","\n")
dimnames(p)<-list(NULL,c("P Estimate"))
surv<-round(c(1,1-cumsum(p)),digits=5)
right <- data$right
if(any(!(is.finite(right)))){
t <- max(right[is.finite(right)])
return(list(time=tau[tau<t],surv=surv[tau<t]))
}
else
return(list(time=tau,surv=surv)) # Retorna a função de sobrevivência
}
# Estimação da função de sobrevivência para 'var_cat' igual a 0 e 1
dat1 = df_surv[df_surv$var_cat == 0,]
dat1$right[is.na(dat1$right)] = Inf
tau = cria.tau(dat1)
p = S.ini(tau = tau)
A = cria.A(data = dat1, tau = tau)
tb1 = Turnbull(p, A, dat1)
dat1 = df_surv[df_surv$var_cat == 1,]
dat1$right[is.na(dat1$right)] = Inf
tau = cria.tau(dat1)
p = S.ini(tau = tau)
A = cria.A(data = dat1, tau = tau)
tb2 = Turnbull(p, A, dat1)
# Visualização das funções de sobrevivência para os dois grupos
par(mfrow = c(1, 1))
plot(tb1$time, tb1$surv, col = "red", type = "s", ylim = c(0, 1), xlim = c(0, 10),
xlab = "Tempo em anos", ylab = "S(t)")
lines(tb2$time, tb2$surv, col = "blue", type = "s")
legend(7.5, 0.9, lty = 1, col = c("red", "blue"), c("Categoria 0", "Categoria 1"),
bty = "n", cex = 0.9)
m = max(summary(df_surv$right))  # Máximo dos valores de censura
li = df_surv$left
ui = ifelse(is.na(df_surv$right), m + 1000, df_surv$right)  # Ajuste para censura direita
# Ajuste do modelo de Cox para a variável categórica
fit1 = ic_sp(cbind(li, ui) ~ var_cat, model = 'ph', bs_samples = 100, data = df_surv)
summary(fit1)
# Ajuste do modelo de Cox para a variável contínua
fit2 = ic_sp(cbind(li, ui) ~ var_cont, model = 'ph', bs_samples = 100, data = df_surv)
summary(fit2)
# Seleção das variáveis com p-valor < 0,25 para a análise multivariada
fit3 = ic_sp(cbind(li, ui) ~ var_cat + var_cont, model = 'ph', bs_samples = 100, data = df_surv)
summary(fit3)
step_icph <- function(model, data) {
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- current_model$llk  # Log-verossimilhança inicial
# Processo iterativo de remoção de variáveis com base na log-verossimilhança
for (var in vars) {
formula_new <- as.formula(paste("cbind(li, ui) ~",
paste(setdiff(vars, var), collapse = " + ")))
model_new <- ic_sp(formula_new, model = "ph", bs_samples = 100, data = data)
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
# Diagnóstico e atualização do modelo
if (new_llk > best_llk) {
best_llk <- new_llk
current_model <- model_new
vars <- setdiff(vars, var)
}
}
return(current_model)  # Retorna o modelo final
}
fit_final = step_icph(fit3)
fit_final = step_icph(fit1)
step_icph <- function(model, data) {
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- current_model$llk  # Log-verossimilhança inicial
# Processo iterativo de remoção de variáveis com base na log-verossimilhança
for (var in vars) {
formula_new <- as.formula(paste("cbind(li, ui) ~",
paste(setdiff(vars, var), collapse = " + ")))
model_new <- ic_sp(formula_new, model = "ph", bs_samples = 100, data = data)
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
# Diagnóstico e atualização do modelo
if (new_llk > best_llk) {
best_llk <- new_llk
current_model <- model_new
vars <- setdiff(vars, var)
}
}
return(current_model)  # Retorna o modelo final
}
fit_final = step_icph(fit1)
step_icph <- function(model, data) {
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- model$llk  # Log-verossimilhança inicial
repeat {
improved <- FALSE  # Flag para indicar se houve melhora
best_model <- current_model  # Mantém o melhor modelo da iteração
for (var in vars) {
formula_new <- as.formula(paste("cbind(li, ui) ~",
paste(setdiff(vars, var), collapse = " + ")))
model_new <- ic_sp(formula_new, model = model$model,
bs_samples = model$bs_samples, data = data)
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
if (new_llk > best_llk) {
best_llk <- new_llk
best_model <- model_new
vars <- setdiff(vars, var)
improved <- TRUE
break  # Sai do loop para reavaliar as variáveis
}
}
if (!improved) break  # Para se nenhuma variável melhorou o modelo
current_model <- best_model  # Atualiza o modelo corrente
}
return(current_model)  # Retorna o modelo final
}
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit1, df_surv)
step_icph <- function(model, data) {
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- model$llk  # Log-verossimilhança inicial
repeat {
improved <- FALSE  # Flag para indicar se houve melhora
best_model <- current_model  # Mantém o melhor modelo da iteração
for (var in vars) {
new_vars <- setdiff(vars, var)  # Remove uma variável
# Se não houver mais variáveis, usa apenas o intercepto
formula_new <- if (length(new_vars) > 0) {
as.formula(paste("cbind(li, ui) ~", paste(new_vars, collapse = " + ")))
} else {
as.formula("cbind(li, ui) ~ 1")  # Modelo apenas com intercepto
}
model_new <- ic_sp(formula_new, model = model$model,
bs_samples = model$bs_samples, data = data)
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
if (new_llk > best_llk) {
best_llk <- new_llk
best_model <- model_new
vars <- new_vars  # Atualiza as variáveis restantes
improved <- TRUE
break  # Sai do loop para reavaliar as variáveis
}
}
if (!improved) break  # Para se nenhuma variável melhorou o modelo
current_model <- best_model  # Atualiza o modelo corrente
}
return(current_model)  # Retorna o modelo final
}
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit1, data)
step_icph <- function(model, data = NULL) {
# Se data não for fornecido, tenta extrair do modelo original
if (is.null(data)) {
data <- model.frame(model)  # Obtém os dados usados no modelo original
}
if (!is.data.frame(data)) {
stop("'data' precisa ser um data.frame válido.")  # Verifica se os dados são válidos
}
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- model$llk  # Log-verossimilhança inicial
repeat {
improved <- FALSE  # Flag para indicar se houve melhora
best_model <- current_model  # Mantém o melhor modelo da iteração
for (var in vars) {
new_vars <- setdiff(vars, var)  # Remove uma variável
# Se não houver mais variáveis, usa apenas o intercepto
formula_new <- if (length(new_vars) > 0) {
as.formula(paste("cbind(li, ui) ~", paste(new_vars, collapse = " + ")))
} else {
as.formula("cbind(li, ui) ~ 1")  # Modelo apenas com intercepto
}
model_new <- ic_sp(formula_new, model = model$model,
bs_samples = model$bs_samples, data = data)
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
if (new_llk > best_llk) {
best_llk <- new_llk
best_model <- model_new
vars <- new_vars  # Atualiza as variáveis restantes
improved <- TRUE
break  # Sai do loop para reavaliar as variáveis
}
}
if (!improved) break  # Para se nenhuma variável melhorou o modelo
current_model <- best_model  # Atualiza o modelo corrente
}
return(current_model)  # Retorna o modelo final
}
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit1, data)
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit1, df_surv)
step_icph <- function(model, data = NULL) {
# Se data não for fornecido, tenta extrair do modelo original
if (is.null(data)) {
data <- model.frame(model)  # Obtém os dados usados no modelo original
}
if (!is.data.frame(data)) {
stop("'data' precisa ser um data.frame válido.")  # Verifica se os dados são válidos
}
vars <- attr(terms(model$formula), "term.labels")  # Variáveis do modelo
current_model <- model
best_llk <- model$llk  # Log-verossimilhança inicial
repeat {
improved <- FALSE  # Flag para indicar se houve melhora
best_model <- current_model  # Mantém o melhor modelo da iteração
for (var in vars) {
new_vars <- setdiff(vars, var)  # Remove uma variável
# Se não houver mais variáveis, usa apenas o intercepto
formula_new <- if (length(new_vars) > 0) {
as.formula(paste("cbind(li, ui) ~", paste(new_vars, collapse = " + ")))
} else {
as.formula("cbind(li, ui) ~ 1")  # Modelo apenas com intercepto
}
# Criando o novo modelo sem bs_samples
model_new <- ic_sp(formula_new, model = "ph", data = data)  # Ajuste do modelo
new_llk <- model_new$llk  # Log-verossimilhança do novo modelo
if (new_llk > best_llk) {
best_llk <- new_llk
best_model <- model_new
vars <- new_vars  # Atualiza as variáveis restantes
improved <- TRUE
break  # Sai do loop para reavaliar as variáveis
}
}
if (!improved) break  # Para se nenhuma variável melhorou o modelo
current_model <- best_model  # Atualiza o modelo corrente
}
return(current_model)  # Retorna o modelo final
}
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit1, df_surv)
# Sumário do modelo final
summary(fit_final)
# Aplicação da função ao modelo inicial
fit_final <- step_icph(fit3, df_surv)
# Sumário do modelo final
summary(fit_final)
install.packages("packrat")
install.packages("rsconnect")
mg16 <- read.csv2("previsão dengue/mg_2016.csv")
library(readr)
library(dplyr)
library(stringr)
library(tools)
# Carrega os dados históricos previamente consolidados
mg16 <- read.csv2("previsão dengue/mg_2016.csv")
mg17 <- read.csv2("previsão dengue/mg_2017.csv")
mg18 <- read.csv2("previsão dengue/mg_2018.csv")
